[2025-01-27T06:04:44.006+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:04:44.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:04:44.014+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:04:44.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:04:49.976+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:04:50.109+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:04:50.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:04:50.215+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:04:50.215+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:04:50.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.327 seconds
[2025-01-27T06:05:21.962+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:05:21.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:05:22.155+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:05:22.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:06:00.389+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:06:00.388+0000] {timeout.py:68} ERROR - Process timed out, PID: 62
[2025-01-27T06:06:00.390+0000] {logging_mixin.py:190} WARNING - Exception ignored in: <bound method _MultipleClassMarker._remove_item of <sqlalchemy.orm.clsregistry._MultipleClassMarker object at 0x7fd34d07f990>>
[2025-01-27T06:06:00.392+0000] {logging_mixin.py:190} WARNING - Traceback (most recent call last):
[2025-01-27T06:06:00.400+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/clsregistry.py", line 157, in _remove_item
[2025-01-27T06:06:00.404+0000] {logging_mixin.py:190} WARNING -     def _remove_item(self, ref):
[2025-01-27T06:06:00.408+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2025-01-27T06:06:00.416+0000] {logging_mixin.py:190} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2025-01-27T06:06:00.419+0000] {logging_mixin.py:190} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pipeline_scraping.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 62
[2025-01-27T06:06:02.859+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:06:03.037+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:06:03.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:06:03.291+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:06:03.291+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:06:03.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 43.161 seconds
[2025-01-27T06:06:33.697+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:06:33.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:06:33.708+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:06:33.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:06:35.293+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:06:35.332+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:06:35.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:06:35.376+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:06:35.376+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:06:35.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.742 seconds
[2025-01-27T06:07:06.029+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:07:06.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:07:06.047+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:07:06.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:07:07.805+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:07:07.844+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:07:07.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:07:07.903+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:07:07.903+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:07:07.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.956 seconds
[2025-01-27T06:07:38.863+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:07:38.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:07:38.870+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:07:38.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:07:40.345+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:07:40.383+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:07:40.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:07:40.422+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:07:40.422+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:07:40.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.624 seconds
[2025-01-27T06:08:10.803+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:08:10.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:08:10.835+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:08:10.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:08:13.529+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:08:13.573+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:08:13.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:08:13.611+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:08:13.611+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:08:13.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.877 seconds
[2025-01-27T06:08:44.653+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:08:44.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:08:44.671+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:08:44.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:08:46.460+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:08:46.513+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:08:46.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:08:46.571+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:08:46.571+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:08:46.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.997 seconds
[2025-01-27T06:09:17.243+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:09:17.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:09:17.281+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:09:17.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:09:19.532+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:09:19.728+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:09:19.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:09:19.910+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:09:19.909+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:09:20.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.855 seconds
[2025-01-27T06:09:51.181+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:09:51.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:09:51.194+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:09:51.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:09:53.400+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:09:53.632+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:09:53.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:09:53.690+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:09:53.689+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:09:53.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.579 seconds
[2025-01-27T06:11:26.839+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:11:26.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:11:26.870+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:11:26.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:11:30.265+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:11:40.132+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:11:40.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:11:40.475+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:11:40.449+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:11:40.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 15.641 seconds
[2025-01-27T06:12:10.890+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:12:10.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:12:10.907+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:12:10.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:12:14.282+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:12:14.736+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:12:14.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:12:14.999+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:12:14.998+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:12:15.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.226 seconds
[2025-01-27T06:14:12.265+0000] {processor.py:186} INFO - Started process (PID=154) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:14:12.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:14:12.292+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:14:12.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:14:17.512+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:14:18.199+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:14:18.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:14:18.525+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:14:18.508+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:14:18.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.769 seconds
[2025-01-27T06:14:49.444+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:14:49.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:14:49.458+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:14:49.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:15:18.281+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:15:18.272+0000] {timeout.py:68} ERROR - Process timed out, PID: 162
[2025-01-27T06:15:18.308+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:15:18.282+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pipeline_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_scraping.py", line 4, in <module>
    from scraping_lm import scraping_etl
  File "/opt/airflow/dags/scraping_lm.py", line 9, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 645, in parent
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pipeline_scraping.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 162
[2025-01-27T06:15:18.310+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:15:18.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 31.686 seconds
[2025-01-27T06:15:49.109+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:15:49.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:15:49.139+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:15:49.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:15:54.519+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:16:34.460+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-27T06:17:29.737+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:17:29.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:17:29.747+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:17:29.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:17:32.579+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:17:33.790+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:17:33.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:17:33.947+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:17:33.946+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:17:34.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.318 seconds
[2025-01-27T06:18:04.269+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:18:04.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:18:04.275+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:18:04.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:18:06.187+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:18:06.240+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:18:06.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:18:06.290+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:18:06.290+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:18:06.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.075 seconds
[2025-01-27T06:18:36.735+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:18:36.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:18:36.741+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:18:36.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:18:38.674+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:18:38.725+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:18:38.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:18:38.779+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:18:38.779+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:18:38.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.104 seconds
[2025-01-27T06:19:09.153+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:09.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:19:09.158+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:09.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:10.895+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:10.942+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:10.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:19:10.990+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:10.989+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:19:11.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.890 seconds
[2025-01-27T06:19:41.424+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:41.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:19:41.433+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:41.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:43.353+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:43.404+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:43.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:19:43.447+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:43.447+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:19:43.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.078 seconds
[2025-01-27T06:19:53.976+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:53.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:19:53.981+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:53.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:55.152+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:19:55.193+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:55.192+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'scraping_etl', 'Task Id': 'testing_scraping', 'Run Id': 'scheduled__2025-01-26T00:00:00+00:00', 'Hostname': 'dfba9d948bec', 'External Executor Id': 'e2eb4baf-2fdc-4afd-9b83-576b4774b8d4'}
[2025-01-27T06:19:55.261+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:55.260+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=scraping_etl, task_id=testing_scraping, run_id=scheduled__2025-01-26T00:00:00+00:00, execution_date=20250126T000000, start_date=20250127T061423, end_date=20250127T061955
[2025-01-27T06:19:55.301+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:55.301+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: scraping_etl.testing_scraping scheduled__2025-01-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2025-01-27T06:19:55.360+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:55.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:19:55.449+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:19:55.448+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:19:55.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.541 seconds
[2025-01-27T06:20:25.869+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:20:25.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:20:25.875+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:20:25.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:20:28.160+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:20:28.384+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:20:28.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:20:28.434+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:20:28.434+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:20:28.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.627 seconds
[2025-01-27T06:21:17.381+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:21:17.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:21:17.407+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:21:17.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:21:21.140+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:21:21.485+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:21:21.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:21:21.577+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:21:21.577+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:21:21.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 12.097 seconds
[2025-01-27T06:21:52.668+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:21:52.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:21:52.678+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:21:52.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:21:54.986+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:21:55.265+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:21:55.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:21:55.352+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:21:55.352+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:21:55.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.803 seconds
[2025-01-27T06:22:25.710+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:22:25.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:22:25.715+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:22:25.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:22:28.254+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:22:28.331+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:22:28.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:22:28.412+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:22:28.411+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:22:28.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.765 seconds
[2025-01-27T06:22:58.921+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:22:58.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:22:58.926+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:22:58.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:23:01.014+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:23:01.107+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:23:01.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:23:01.159+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:23:01.158+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:23:01.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.288 seconds
[2025-01-27T06:23:31.619+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:23:31.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:23:31.625+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:23:31.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:23:33.755+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:23:33.819+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:23:33.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:23:33.879+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:23:33.879+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:23:33.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.321 seconds
[2025-01-27T06:24:04.142+0000] {processor.py:186} INFO - Started process (PID=281) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:24:04.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:24:04.149+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:24:04.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:24:06.444+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:24:06.528+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:24:06.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:24:06.581+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:24:06.581+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:24:06.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.502 seconds
[2025-01-27T06:24:37.145+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:24:37.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:24:37.153+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:24:37.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:24:38.043+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:24:38.103+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:24:38.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:24:38.185+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:24:38.184+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:24:38.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.992 seconds
[2025-01-27T06:25:08.728+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:25:08.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:25:08.738+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:25:08.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:25:11.679+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:25:12.723+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:25:12.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:25:12.823+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:25:12.822+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:25:12.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.180 seconds
[2025-01-27T06:25:43.039+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:25:43.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:25:43.043+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:25:43.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:25:45.571+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:25:45.737+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:25:45.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:25:45.827+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:25:45.826+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:25:45.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.870 seconds
[2025-01-27T06:26:16.250+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:26:16.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:26:16.256+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:16.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:26:18.022+0000] {processor.py:925} INFO - DAG(s) 'scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:26:18.077+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:18.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:26:18.126+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:18.125+0000] {dag.py:4180} INFO - Setting next_dagrun for scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:26:18.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.943 seconds
[2025-01-27T06:26:32.842+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:26:32.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:26:32.849+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:32.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:26:33.512+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:26:33.873+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.872+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:testing_scraping_etl
[2025-01-27T06:26:33.897+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.896+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:testing_scraping_etl
[2025-01-27T06:26:33.912+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.911+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:testing_scraping_etl
[2025-01-27T06:26:33.930+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.930+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:testing_scraping_etl
[2025-01-27T06:26:33.946+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.946+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:testing_scraping_etl
[2025-01-27T06:26:33.962+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.961+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:testing_scraping_etl
[2025-01-27T06:26:33.978+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.977+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:testing_scraping_etl
[2025-01-27T06:26:33.980+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:33.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:26:34.010+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:34.009+0000] {dag.py:3262} INFO - Creating ORM DAG for testing_scraping_etl
[2025-01-27T06:26:34.037+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:26:34.036+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-26 00:00:00+00:00, run_after=2025-01-27 00:00:00+00:00
[2025-01-27T06:26:34.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.638 seconds
[2025-01-27T06:27:16.971+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:27:16.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:27:16.983+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:27:16.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:27:21.856+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:27:22.444+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:27:22.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:27:22.587+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:27:22.587+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:27:22.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.954 seconds
[2025-01-27T06:28:35.689+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:28:35.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:28:35.711+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:28:35.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:28:39.845+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:28:40.219+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:28:40.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:28:40.318+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:28:40.317+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:28:40.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.891 seconds
[2025-01-27T06:29:11.003+0000] {processor.py:186} INFO - Started process (PID=349) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:29:11.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:29:11.020+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:29:11.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:29:15.552+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:29:16.397+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:29:16.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:29:16.718+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:29:16.718+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:29:16.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.029 seconds
[2025-01-27T06:30:21.423+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:30:21.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:30:21.449+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:30:21.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:30:26.684+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:30:27.033+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:30:27.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:30:27.202+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:30:27.201+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:30:27.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.072 seconds
[2025-01-27T06:30:57.861+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:30:57.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:30:57.867+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:30:57.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:31:00.476+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:31:00.556+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:31:00.555+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:31:00.600+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:31:00.600+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:31:00.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.791 seconds
[2025-01-27T06:31:30.855+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:31:30.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:31:30.863+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:31:30.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:31:33.051+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:31:33.122+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:31:33.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:31:33.177+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:31:33.177+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:31:33.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.379 seconds
[2025-01-27T06:32:45.780+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:32:45.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:32:45.868+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:32:45.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:32:57.360+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:23.075+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:23.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:34:23.086+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:34:23.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:25.414+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:25.538+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:34:25.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:34:25.606+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:34:25.605+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:34:25.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.597 seconds
[2025-01-27T06:34:55.983+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:55.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:34:56.006+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:34:56.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:58.154+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:34:58.212+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:34:58.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:34:58.288+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:34:58.287+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:34:58.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.399 seconds
[2025-01-27T06:35:28.696+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:35:28.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:35:28.707+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:35:28.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:35:30.295+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:35:30.381+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:35:30.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:35:30.483+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:35:30.482+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:35:30.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.868 seconds
[2025-01-27T06:36:00.865+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:36:00.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:36:00.870+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:36:00.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:36:02.527+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:36:02.575+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:36:02.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:36:02.626+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:36:02.625+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:36:02.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.834 seconds
[2025-01-27T06:36:33.070+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:36:33.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:36:33.091+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:36:33.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:36:35.163+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:36:35.225+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:36:35.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:36:35.287+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:36:35.286+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:36:35.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.303 seconds
[2025-01-27T06:37:05.528+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:37:05.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:37:05.534+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:37:05.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:37:07.404+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:37:07.484+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:37:07.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:37:07.561+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:37:07.560+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:37:07.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.116 seconds
[2025-01-27T06:37:38.201+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:37:38.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:37:38.210+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:37:38.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:37:39.876+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:37:39.958+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:37:39.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:37:40.042+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:37:40.041+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:37:40.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.919 seconds
[2025-01-27T06:38:11.475+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:38:10.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:38:10.342+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:38:10.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:38:15.974+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:38:16.579+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:38:16.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:38:16.945+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:38:16.944+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:43:07.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 11.304 seconds
[2025-01-27T06:43:42.697+0000] {processor.py:186} INFO - Started process (PID=466) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:43:42.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:43:42.705+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:43:42.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:43:44.372+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:43:44.426+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:43:44.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:43:44.474+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:43:44.473+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:43:44.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.836 seconds
[2025-01-27T06:44:14.776+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:44:14.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:44:14.782+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:44:14.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:44:16.015+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:44:16.067+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:44:16.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:44:16.112+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:44:16.111+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:44:16.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.387 seconds
[2025-01-27T06:44:46.469+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:44:46.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:44:46.474+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:44:46.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:44:47.603+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:44:47.644+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:44:47.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:44:47.685+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:44:47.685+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:44:47.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.265 seconds
[2025-01-27T06:45:18.242+0000] {processor.py:186} INFO - Started process (PID=490) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:45:18.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:45:18.248+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:45:18.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:45:19.580+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:45:19.649+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:45:19.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:45:19.709+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:45:19.709+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:45:19.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.514 seconds
[2025-01-27T06:45:50.444+0000] {processor.py:186} INFO - Started process (PID=498) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:45:50.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:45:50.454+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:45:50.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:45:52.835+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:45:53.013+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:45:53.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:45:53.090+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:45:53.089+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:45:53.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.492 seconds
[2025-01-27T06:46:23.865+0000] {processor.py:186} INFO - Started process (PID=506) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:46:23.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:46:23.873+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:46:23.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:46:25.243+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:46:25.303+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:46:25.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:46:25.366+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:46:25.366+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:46:25.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.553 seconds
[2025-01-27T06:46:55.546+0000] {processor.py:186} INFO - Started process (PID=514) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:46:55.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:46:55.551+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:46:55.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:46:56.654+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:46:56.697+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:46:56.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:46:56.764+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:46:56.764+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:46:56.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.284 seconds
[2025-01-27T06:47:27.353+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:47:27.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:47:27.360+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:47:27.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:47:28.739+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:47:28.792+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:47:28.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:47:28.854+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:47:28.854+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:47:28.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.577 seconds
[2025-01-27T06:47:59.527+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:47:59.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:47:59.535+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:47:59.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:48:00.660+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:48:00.709+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:48:00.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:48:00.754+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:48:00.753+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:48:00.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.277 seconds
[2025-01-27T06:48:31.553+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:48:31.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:48:31.561+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:48:31.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:48:32.460+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:48:32.504+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:48:32.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:48:32.559+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:48:32.558+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:48:32.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.072 seconds
[2025-01-27T06:49:03.253+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:49:03.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:49:03.259+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:49:03.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:49:04.267+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:49:04.314+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:49:04.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:49:04.359+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:49:04.359+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:49:04.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.158 seconds
[2025-01-27T06:49:34.798+0000] {processor.py:186} INFO - Started process (PID=559) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:49:34.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:49:34.803+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:49:34.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:49:35.701+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:49:35.764+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:49:35.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:49:35.816+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:49:35.816+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:49:35.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.078 seconds
[2025-01-27T06:50:06.565+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:50:06.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:50:06.571+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:50:06.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:50:07.951+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:50:08.011+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:50:08.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:50:08.059+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:50:08.058+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:50:08.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.570 seconds
[2025-01-27T06:50:38.276+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:50:38.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:50:38.287+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:50:38.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:50:39.845+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:50:39.898+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:50:39.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:50:39.958+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:50:39.957+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:50:39.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.740 seconds
[2025-01-27T06:51:10.484+0000] {processor.py:186} INFO - Started process (PID=583) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:51:10.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:51:10.491+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:51:10.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:51:12.212+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:51:12.275+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:51:12.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:51:12.337+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:51:12.336+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:51:12.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.929 seconds
[2025-01-27T06:51:42.956+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:51:42.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:51:42.965+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:51:42.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:51:45.755+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:51:45.804+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:51:45.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:51:45.856+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:51:45.856+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:51:45.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.600 seconds
[2025-01-27T06:52:17.247+0000] {processor.py:186} INFO - Started process (PID=599) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:52:17.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:52:17.254+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:52:17.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:52:20.425+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:52:20.534+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:52:20.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:52:20.608+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:52:20.608+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:52:20.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.464 seconds
[2025-01-27T06:52:51.222+0000] {processor.py:186} INFO - Started process (PID=614) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:52:51.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:52:51.231+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:52:51.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:52:55.966+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:52:56.100+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:52:56.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:52:56.173+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:52:56.165+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:52:56.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 5.044 seconds
[2025-01-27T06:53:26.992+0000] {processor.py:186} INFO - Started process (PID=622) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:53:26.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:53:26.997+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:53:26.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:53:28.308+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:53:28.419+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:53:28.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:53:28.543+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:53:28.543+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:53:28.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.609 seconds
[2025-01-27T06:53:59.027+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:53:59.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:53:59.039+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:53:59.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:54:01.185+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:54:01.276+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:54:01.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:54:01.358+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:54:01.357+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:54:01.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.419 seconds
[2025-01-27T06:54:31.757+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:54:31.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:54:31.763+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:54:31.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:54:37.321+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:54:37.536+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:54:37.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:54:37.720+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:54:37.719+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:54:37.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.117 seconds
[2025-01-27T06:55:08.627+0000] {processor.py:186} INFO - Started process (PID=646) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:55:08.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:55:08.637+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:55:08.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:55:11.199+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:55:11.301+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:55:11.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:55:11.401+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:55:11.400+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:55:11.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.984 seconds
[2025-01-27T06:55:41.698+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:55:41.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:55:41.707+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:55:41.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:55:44.399+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:55:44.478+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:55:44.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:55:44.586+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:55:44.585+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:55:44.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.980 seconds
[2025-01-27T06:56:15.378+0000] {processor.py:186} INFO - Started process (PID=662) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:56:15.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:56:15.384+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:56:15.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:56:16.587+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:56:16.633+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:56:16.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:56:16.679+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:56:16.679+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:56:16.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.367 seconds
[2025-01-27T06:56:47.050+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:56:47.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:56:47.058+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:56:47.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:56:48.166+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:56:48.208+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:56:48.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:56:48.269+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:56:48.268+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:56:48.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.275 seconds
[2025-01-27T06:57:18.847+0000] {processor.py:186} INFO - Started process (PID=684) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:57:18.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:57:18.855+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:57:18.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:57:20.525+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:57:20.591+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:57:20.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:57:20.654+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:57:20.654+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:57:20.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.874 seconds
[2025-01-27T06:57:51.279+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:57:51.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:57:51.289+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:57:51.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:57:52.577+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:57:52.629+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:57:52.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:57:52.700+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:57:52.700+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:57:52.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.506 seconds
[2025-01-27T06:58:23.433+0000] {processor.py:186} INFO - Started process (PID=702) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:58:23.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:58:23.439+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:58:23.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:58:24.547+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:58:24.595+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:58:24.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:58:24.640+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:58:24.640+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:58:24.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.253 seconds
[2025-01-27T06:58:55.351+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:58:55.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:58:55.400+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:58:55.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:59:00.838+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:59:01.033+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:59:01.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:59:01.273+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:59:01.272+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:59:01.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 7.122 seconds
[2025-01-27T06:59:31.929+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:59:31.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T06:59:31.936+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:59:31.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:59:36.116+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T06:59:36.406+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:59:36.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T06:59:36.564+0000] {logging_mixin.py:190} INFO - [2025-01-27T06:59:36.563+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T06:59:36.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.819 seconds
[2025-01-27T07:00:07.127+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:00:07.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:00:07.133+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:00:07.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:00:10.019+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:00:10.149+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:00:10.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:00:10.254+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:00:10.253+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:00:10.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.216 seconds
[2025-01-27T07:00:40.707+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:00:40.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:00:40.719+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:00:40.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:00:45.656+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:00:45.856+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:00:45.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:00:45.941+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:00:45.940+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:00:45.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 5.317 seconds
[2025-01-27T07:01:16.493+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:01:16.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:01:16.512+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:01:16.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:01:23.340+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:01:23.598+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:01:23.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:01:23.893+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:01:23.882+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:01:24.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 7.630 seconds
[2025-01-27T07:01:54.261+0000] {processor.py:186} INFO - Started process (PID=754) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:01:54.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:01:54.267+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:01:54.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:01:55.810+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:01:55.854+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:01:55.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:01:55.918+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:01:55.918+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:01:55.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.721 seconds
[2025-01-27T07:02:26.496+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:02:26.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:02:26.502+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:02:26.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:02:27.786+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:02:27.828+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:02:27.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:02:27.873+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:02:27.872+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:02:27.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.424 seconds
[2025-01-27T07:02:58.085+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:02:58.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:02:58.090+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:02:58.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:02:59.437+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:02:59.489+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:02:59.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:02:59.537+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:02:59.536+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:02:59.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.498 seconds
[2025-01-27T07:03:30.214+0000] {processor.py:186} INFO - Started process (PID=778) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:03:30.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:03:30.219+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:03:30.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:03:31.893+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:03:31.957+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:03:31.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:03:32.000+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:03:32.000+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:03:32.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.855 seconds
[2025-01-27T07:04:03.049+0000] {processor.py:186} INFO - Started process (PID=786) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:04:03.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:04:03.169+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:04:03.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:04:08.859+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:04:09.195+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:04:09.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:04:09.457+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:04:09.456+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:04:09.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 6.651 seconds
[2025-01-27T07:04:40.096+0000] {processor.py:186} INFO - Started process (PID=800) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:04:40.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:04:40.115+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:04:40.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:04:42.322+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:04:42.424+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:04:42.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:04:42.505+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:04:42.505+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:04:42.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.504 seconds
[2025-01-27T07:05:12.969+0000] {processor.py:186} INFO - Started process (PID=808) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:05:12.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:05:12.976+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:05:12.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:05:14.438+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:05:14.530+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:05:14.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:05:14.649+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:05:14.648+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:05:14.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.762 seconds
[2025-01-27T07:05:45.120+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:05:45.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:05:45.129+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:05:45.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:05:45.645+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:05:45.728+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:05:45.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:05:45.784+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:05:45.784+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:05:45.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.768 seconds
[2025-01-27T07:06:16.107+0000] {processor.py:186} INFO - Started process (PID=824) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:06:16.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:06:16.113+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:06:16.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:06:18.037+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:06:18.091+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:06:18.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:06:18.150+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:06:18.149+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:06:18.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.114 seconds
[2025-01-27T07:06:48.724+0000] {processor.py:186} INFO - Started process (PID=832) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:06:48.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:06:48.732+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:06:48.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:06:50.404+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:06:50.464+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:06:50.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:06:50.523+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:06:50.522+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:06:50.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.859 seconds
[2025-01-27T07:07:21.607+0000] {processor.py:186} INFO - Started process (PID=840) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:07:21.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:07:21.618+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:07:21.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:11:11.381+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:11:11.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:11:11.392+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:11:11.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:11:19.480+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:11:19.826+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:11:19.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:11:20.047+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:11:20.045+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:11:20.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 8.851 seconds
[2025-01-27T07:13:03.262+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:13:03.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:13:03.276+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:13:03.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:13:05.478+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:13:05.586+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:13:05.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:13:05.691+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:13:05.690+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:13:05.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.487 seconds
[2025-01-27T07:13:36.709+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:13:36.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:13:36.756+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:13:36.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:13:40.829+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:13:40.896+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:13:40.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:13:40.963+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:13:40.962+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:13:41.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.351 seconds
[2025-01-27T07:14:11.201+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:14:11.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:14:11.213+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:14:11.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:14:14.120+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:14:14.156+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:14:14.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:14:14.198+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:14:14.198+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:14:14.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.047 seconds
[2025-01-27T07:14:45.485+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:14:45.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:14:45.552+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:14:45.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:15:15.746+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:15:15.732+0000] {timeout.py:68} ERROR - Process timed out, PID: 72
[2025-01-27T07:15:15.810+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:15:15.749+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pipeline_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_scraping.py", line 4, in <module>
    from scraping_lm import scraping_etl
  File "/opt/airflow/dags/scraping_lm.py", line 9, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.accessors import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/arrow/accessors.py", line 23, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 336, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 333, in _make_global_functions
    g[cpp_name] = g[name] = _wrap_function(name, func)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 304, in _wrap_function
    return _decorate_compute_function(wrapper, name, func, options_class)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 124, in _decorate_compute_function
    cpp_doc = func._doc
              ^^^^^^^^^
  File "pyarrow/_compute.pyx", line 341, in pyarrow._compute.Function._doc.__get__
  File "<string>", line 1, in <lambda>
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pipeline_scraping.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 72
[2025-01-27T07:15:15.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:15:25.876+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-27T07:15:57.434+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:15:57.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:15:57.442+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:15:57.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:15:59.575+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:15:59.630+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:15:59.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:15:59.676+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:15:59.676+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:15:59.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.290 seconds
[2025-01-27T07:16:30.920+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:16:30.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:16:30.961+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:16:30.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:17:56.888+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:17:56.841+0000] {timeout.py:68} ERROR - Process timed out, PID: 90
[2025-01-27T07:18:14.367+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:18:14.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:18:14.376+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:18:14.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:18:17.849+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:18:18.627+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:18:18.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:18:18.670+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:18:18.669+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:18:18.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.410 seconds
[2025-01-27T07:18:49.099+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:18:49.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:18:49.106+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:18:49.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:18:51.622+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:18:52.082+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:18:52.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:18:52.241+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:18:52.227+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:18:52.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.356 seconds
[2025-01-27T07:19:23.203+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:19:23.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:19:23.222+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:19:23.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:19:34.781+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:19:35.127+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:19:35.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:19:35.216+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:19:35.215+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:19:35.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 13.156 seconds
[2025-01-27T07:20:45.427+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:20:45.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:20:45.460+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:20:45.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:20:48.901+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:20:49.227+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:20:49.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:20:49.319+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:20:49.319+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:20:49.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.642 seconds
[2025-01-27T07:21:20.051+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:21:20.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:21:20.066+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:21:20.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:09.439+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:09.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:23:09.531+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:23:09.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:13.006+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:13.761+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:23:13.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:23:13.845+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:23:13.845+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:23:13.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.633 seconds
[2025-01-27T07:23:44.726+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:44.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:23:44.733+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:23:44.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:46.881+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:23:47.186+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:23:47.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:23:47.256+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:23:47.255+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:23:47.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.612 seconds
[2025-01-27T07:24:18.098+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:24:18.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:24:18.113+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:24:18.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:24:22.898+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:24:23.223+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:24:23.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:24:23.303+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:24:23.302+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:24:23.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 5.333 seconds
[2025-01-27T07:24:28.959+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:24:28.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:24:28.984+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:24:28.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:25:21.541+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:00.572+0000] {timeout.py:68} ERROR - Process timed out, PID: 152
[2025-01-27T07:25:22.502+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:25:22.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:25:22.513+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:22.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:25:26.155+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:25:26.453+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:26.442+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'testing_scraping_etl', 'Task Id': 'testing_scraping', 'Run Id': 'manual__2025-01-27T07:18:45.798672+00:00', 'Hostname': '6d90e7596ae2', 'External Executor Id': '8fe18d31-b893-4ce4-9c87-1dc9065397be'}
[2025-01-27T07:25:26.547+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:26.546+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=testing_scraping_etl, task_id=testing_scraping, run_id=manual__2025-01-27T07:18:45.798672+00:00, execution_date=20250127T071845, start_date=20250127T071856, end_date=20250127T072526
[2025-01-27T07:25:26.631+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:26.630+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: testing_scraping_etl.testing_scraping manual__2025-01-27T07:18:45.798672+00:00 [up_for_retry]> in state up_for_retry
[2025-01-27T07:25:27.214+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:27.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:25:27.304+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:27.303+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:25:27.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 4.925 seconds
[2025-01-27T07:25:58.562+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:25:58.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:25:58.584+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:25:58.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:26:36.053+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:26:36.052+0000] {timeout.py:68} ERROR - Process timed out, PID: 168
[2025-01-27T07:26:36.189+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:26:36.071+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pipeline_scraping.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_scraping.py", line 4, in <module>
    from scraping_lm import scraping_etl
  File "/opt/airflow/dags/scraping_lm.py", line 1, in <module>
    from selenium import webdriver
  File "/home/airflow/.local/lib/python3.12/site-packages/selenium/webdriver/__init__.py", line 29, in <module>
    from .firefox.firefox_profile import FirefoxProfile  # noqa
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/selenium/webdriver/firefox/firefox_profile.py", line 29, in <module>
    from xml.dom import minidom
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pipeline_scraping.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.4/best-practices.html#reducing-dag-complexity, PID: 168
[2025-01-27T07:26:36.216+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:26:36.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 39.314 seconds
[2025-01-27T07:27:06.876+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:27:06.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:27:06.887+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:27:06.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:27:10.173+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:27:10.377+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:27:10.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:27:10.471+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:27:10.471+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:27:10.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 3.699 seconds
[2025-01-27T07:27:41.164+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:27:41.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:27:41.187+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:27:41.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:27:48.133+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:28:18.282+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-01-27T07:29:18.269+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:29:18.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:29:18.282+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:29:18.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:29:48.927+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:29:48.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:29:48.942+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:29:48.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:29:50.793+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:29:51.107+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:29:51.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:29:51.145+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:29:51.144+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:29:51.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.269 seconds
[2025-01-27T07:30:21.428+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:30:21.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:30:21.436+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:30:21.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:30:23.163+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:30:23.208+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:30:23.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:30:23.244+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:30:23.243+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:30:23.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.865 seconds
[2025-01-27T07:30:53.773+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:30:53.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:30:53.779+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:30:53.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:30:55.324+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:30:55.360+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:30:55.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:30:55.398+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:30:55.398+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:30:55.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.670 seconds
[2025-01-27T07:31:25.674+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:31:25.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:31:25.681+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:31:25.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:31:27.207+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:31:27.254+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:31:27.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:31:27.291+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:31:27.291+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:31:27.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.660 seconds
[2025-01-27T07:31:57.611+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:31:57.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:31:57.621+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:31:57.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:31:59.408+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:31:59.471+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:31:59.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:31:59.513+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:31:59.513+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:31:59.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.962 seconds
[2025-01-27T07:32:29.994+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:32:29.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:32:30.002+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:32:30.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:32:31.698+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:32:31.816+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:32:31.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:32:31.885+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:32:31.885+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:32:31.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.952 seconds
[2025-01-27T07:33:02.455+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:33:02.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:33:02.462+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:33:02.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:33:04.041+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:33:04.086+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:33:04.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:33:04.132+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:33:04.132+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:33:04.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.731 seconds
[2025-01-27T07:33:34.415+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:33:34.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:33:34.423+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:33:34.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:33:35.967+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:33:36.019+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:33:36.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:33:36.071+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:33:36.070+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:33:36.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.705 seconds
[2025-01-27T07:34:06.527+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:34:06.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:34:06.535+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:34:06.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:34:07.903+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:34:07.951+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:34:07.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:34:07.996+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:34:07.996+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:34:08.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.519 seconds
[2025-01-27T07:34:39.865+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:34:39.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:34:39.958+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:34:39.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:34:41.637+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:34:41.684+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:34:41.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:34:41.726+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:34:41.726+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:34:41.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.936 seconds
[2025-01-27T07:35:12.063+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:35:12.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:35:12.071+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:35:12.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:35:13.400+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:35:13.463+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:35:13.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:35:13.522+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:35:13.521+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:35:13.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.517 seconds
[2025-01-27T07:35:43.707+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:35:43.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:35:43.714+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:35:43.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:35:45.047+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:35:45.087+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:35:45.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:35:45.132+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:35:45.132+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:35:45.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.482 seconds
[2025-01-27T07:36:15.398+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:36:15.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:36:15.407+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:36:15.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:36:16.789+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:36:16.850+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:36:16.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:36:16.912+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:36:16.912+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:36:16.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.575 seconds
[2025-01-27T07:36:47.502+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:36:47.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:36:47.511+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:36:47.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:36:49.121+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:36:49.253+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:36:49.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:36:49.310+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:36:49.309+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:36:49.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.863 seconds
[2025-01-27T07:37:19.836+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:37:19.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:37:19.846+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:37:19.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:37:21.027+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:37:21.076+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:37:21.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:37:21.131+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:37:21.130+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:37:21.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.356 seconds
[2025-01-27T07:37:51.685+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:37:51.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:37:51.691+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:37:51.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:37:52.887+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:37:52.932+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:37:52.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:37:52.981+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:37:52.981+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:37:53.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.344 seconds
[2025-01-27T07:38:23.422+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:38:23.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:38:23.429+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:38:23.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:38:24.570+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:38:24.610+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:38:24.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:38:24.653+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:38:24.653+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:38:24.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.276 seconds
[2025-01-27T07:38:54.857+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:38:54.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:38:54.864+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:38:54.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:38:56.103+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:38:56.166+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:38:56.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:38:56.215+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:38:56.214+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:38:56.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.404 seconds
[2025-01-27T07:39:26.488+0000] {processor.py:186} INFO - Started process (PID=189) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:39:26.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:39:26.495+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:39:26.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:39:26.667+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:39:26.708+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:39:26.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:39:26.749+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:39:26.749+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:39:26.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.353 seconds
[2025-01-27T07:39:57.000+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:39:57.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:39:57.007+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:39:57.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:39:58.189+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:39:58.229+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:39:58.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:39:58.274+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:39:58.273+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:39:58.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.324 seconds
[2025-01-27T07:40:28.655+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:40:28.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:40:28.662+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:40:28.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:40:29.740+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:40:29.780+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:40:29.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:40:29.822+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:40:29.822+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:40:29.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.210 seconds
[2025-01-27T07:41:00.118+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:41:00.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:41:00.129+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:41:00.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:41:01.429+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:41:01.555+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:41:01.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:41:01.619+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:41:01.618+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:41:01.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.557 seconds
[2025-01-27T07:41:32.163+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:41:32.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:41:32.170+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:41:32.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:41:33.548+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:41:33.620+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:41:33.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:41:33.701+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:41:33.701+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:41:33.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.596 seconds
[2025-01-27T07:42:04.072+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:42:04.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:42:04.079+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:42:04.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:42:05.401+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:42:05.443+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:42:05.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:42:05.484+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:42:05.483+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:42:05.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.457 seconds
[2025-01-27T07:42:35.644+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:42:35.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:42:35.651+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:42:35.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:42:36.746+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:42:36.802+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:42:36.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:42:36.860+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:42:36.859+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:42:36.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.274 seconds
[2025-01-27T07:43:07.073+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:43:07.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T07:43:07.083+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:43:07.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:43:08.433+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T07:43:08.473+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:43:08.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T07:43:08.525+0000] {logging_mixin.py:190} INFO - [2025-01-27T07:43:08.524+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T07:43:08.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 1.512 seconds
[2025-01-27T08:00:38.321+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:00:38.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T08:00:38.345+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:00:38.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:00:43.769+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:00:44.007+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:00:44.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T08:00:44.250+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:00:44.236+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T08:00:44.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 7.309 seconds
[2025-01-27T08:11:19.081+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:11:19.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T08:11:19.188+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:11:19.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:11:25.729+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:11:38.911+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:11:38.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T08:11:39.344+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:11:39.343+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T08:11:39.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 21.893 seconds
[2025-01-27T08:12:10.352+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:12:10.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T08:12:10.368+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:12:10.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:12:12.748+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:12:12.972+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:12:12.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T08:12:13.079+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:12:13.078+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T08:12:13.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.837 seconds
[2025-01-27T08:12:43.323+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:12:43.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pipeline_scraping.py for tasks to queue
[2025-01-27T08:12:43.338+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:12:43.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:12:45.983+0000] {processor.py:925} INFO - DAG(s) 'testing_scraping_etl' retrieved from /opt/airflow/dags/pipeline_scraping.py
[2025-01-27T08:12:46.135+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:12:46.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-27T08:12:46.189+0000] {logging_mixin.py:190} INFO - [2025-01-27T08:12:46.189+0000] {dag.py:4180} INFO - Setting next_dagrun for testing_scraping_etl to 2025-01-27 00:00:00+00:00, run_after=2025-01-28 00:00:00+00:00
[2025-01-27T08:12:46.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pipeline_scraping.py took 2.939 seconds
